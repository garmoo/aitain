{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aabc0a1-fad4-42db-aec5-84e31c2d388b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T11:28:17.194615Z",
     "iopub.status.busy": "2025-10-28T11:28:17.194368Z",
     "iopub.status.idle": "2025-10-28T11:28:17.199817Z",
     "shell.execute_reply": "2025-10-28T11:28:17.199447Z",
     "shell.execute_reply.started": "2025-10-28T11:28:17.194600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"]= \"https://hf-mirror.com\"\n",
    "os.environ['HF_HOME'] = '/mnt/new_volume/hf'\n",
    "os.environ['HF_HUB_CACHE'] = '/mnt/new_volume/hf/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c404d5a-4f02-4b9e-8909-862c246ffa21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T11:28:34.520242Z",
     "iopub.status.busy": "2025-10-28T11:28:34.519977Z",
     "iopub.status.idle": "2025-10-28T11:32:25.669318Z",
     "shell.execute_reply": "2025-10-28T11:32:25.668933Z",
     "shell.execute_reply.started": "2025-10-28T11:28:34.520227Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 19:28:37.225452: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-28 19:28:37.264346: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-28 19:28:38.226937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://hf-mirror.com/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e07941c0f27446383c11f3eef55908e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b5a40220ed43d8b659ea1536a37099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2982ce4cb3814743a3776c3d19809b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d161b22375e4cecbd7d076a6f9afb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8957214951515198}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# 仅指定任务时，使用默认模型（不推荐）\n",
    "pipe = pipeline(\"sentiment-analysis\")\n",
    "pipe(\"今儿上海可真冷啊\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630b6fdc-1c32-4e43-8f66-d81fd8e11add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T11:35:51.053022Z",
     "iopub.status.busy": "2025-10-28T11:35:51.052557Z",
     "iopub.status.idle": "2025-10-28T11:35:51.060314Z",
     "shell.execute_reply": "2025-10-28T11:35:51.059968Z",
     "shell.execute_reply.started": "2025-10-28T11:35:51.053002Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9238728284835815}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"我觉得这家店蒜泥白肉的味道一般\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94bf2d7e-7162-4a46-9016-409cb0f6f174",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-10-28T11:36:28.907255Z",
     "iopub.status.busy": "2025-10-28T11:36:28.906986Z",
     "iopub.status.idle": "2025-10-28T11:36:28.914397Z",
     "shell.execute_reply": "2025-10-28T11:36:28.914028Z",
     "shell.execute_reply.started": "2025-10-28T11:36:28.907237Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8578683137893677}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认使用的模型 distilbert-base-uncased-finetuned-sst-2-english \n",
    "# 并未针对中文做太多训练，中文的文本分类任务表现未必满意\n",
    "pipe(\"你学东西真的好快，理论课一讲就明白了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ea8423-a593-4112-9ce0-2987f5c00640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T11:37:38.517430Z",
     "iopub.status.busy": "2025-10-28T11:37:38.517183Z",
     "iopub.status.idle": "2025-10-28T11:37:38.523983Z",
     "shell.execute_reply": "2025-10-28T11:37:38.523633Z",
     "shell.execute_reply.started": "2025-10-28T11:37:38.517414Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9961802959442139}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 替换为英文后，文本分类任务的表现立刻改善\n",
    "pipe(\"You learn things really quickly. You understand the theory class as soon as it is taught.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec38be5-ea2f-4a9c-b3fc-77ec757b0e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T11:37:50.288330Z",
     "iopub.status.busy": "2025-10-28T11:37:50.288057Z",
     "iopub.status.idle": "2025-10-28T11:37:50.296192Z",
     "shell.execute_reply": "2025-10-28T11:37:50.295788Z",
     "shell.execute_reply.started": "2025-10-28T11:37:50.288313Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995032548904419}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Today Shanghai is really cold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac5de0a-016f-419a-ad36-0f0f31287d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T11:38:03.321174Z",
     "iopub.status.busy": "2025-10-28T11:38:03.320916Z",
     "iopub.status.idle": "2025-10-28T11:38:03.337710Z",
     "shell.execute_reply": "2025-10-28T11:38:03.337299Z",
     "shell.execute_reply.started": "2025-10-28T11:38:03.321158Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995032548904419},\n",
       " {'label': 'NEGATIVE', 'score': 0.9984821677207947},\n",
       " {'label': 'POSITIVE', 'score': 0.9961802959442139}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"Today Shanghai is really cold.\",\n",
    "    \"I think the taste of the garlic mashed pork in this store is average.\",\n",
    "    \"You learn things really quickly. You understand the theory class as soon as it is taught.\"\n",
    "]\n",
    "\n",
    "pipe(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be71dd02-41cd-4eb0-95fa-87ff33648168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:00:55.170986Z",
     "iopub.status.busy": "2025-10-28T12:00:55.170671Z",
     "iopub.status.idle": "2025-10-28T12:00:56.351183Z",
     "shell.execute_reply": "2025-10-28T12:00:56.350746Z",
     "shell.execute_reply.started": "2025-10-28T12:00:55.170972Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://hf-mirror.com/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09852cc7-5e16-4cb4-a1fd-cdaa9d2742f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:19:49.085975Z",
     "iopub.status.busy": "2025-10-28T12:19:49.085732Z",
     "iopub.status.idle": "2025-10-28T12:19:49.107954Z",
     "shell.execute_reply": "2025-10-28T12:19:49.107550Z",
     "shell.execute_reply.started": "2025-10-28T12:19:49.085960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4cfb5f-5403-4e90-b29b-656b6458a185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:19:59.738564Z",
     "iopub.status.busy": "2025-10-28T12:19:59.738303Z",
     "iopub.status.idle": "2025-10-28T12:20:00.936710Z",
     "shell.execute_reply": "2025-10-28T12:20:00.936313Z",
     "shell.execute_reply.started": "2025-10-28T12:19:59.738549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://hf-mirror.com/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "/usr/local/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9674638,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 0,\n",
       "  'end': 12},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.99828726,\n",
       "  'word': 'French',\n",
       "  'start': 18,\n",
       "  'end': 24},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99896103,\n",
       "  'word': 'New York City',\n",
       "  'start': 42,\n",
       "  'end': 55}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\", grouped_entities=True)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83cf5605-364b-409c-b60d-6f267f31e2e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:22:01.672150Z",
     "iopub.status.busy": "2025-10-28T12:22:01.671871Z",
     "iopub.status.idle": "2025-10-28T12:25:46.759957Z",
     "shell.execute_reply": "2025-10-28T12:25:46.759556Z",
     "shell.execute_reply.started": "2025-10-28T12:22:01.672133Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://hf-mirror.com/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced32e84b4d94d52b2f51fa1922bbd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588540bdabc644728e1d2ba89ddb0371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69144d644f84bec8bdb3e8991e9fdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523b0b9b746d4cf88428bfa1b6781a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0c9014cc9143f5a22d772d9f6dc125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(task=\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f50e61c-2c40-448c-849c-878c588e3b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:26:07.233352Z",
     "iopub.status.busy": "2025-10-28T12:26:07.233071Z",
     "iopub.status.idle": "2025-10-28T12:26:07.251321Z",
     "shell.execute_reply": "2025-10-28T12:26:07.250922Z",
     "shell.execute_reply.started": "2025-10-28T12:26:07.233337Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9333, start: 30, end: 54, answer: huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2b5e56-0752-4cdb-92bd-375f1018958a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:26:42.500524Z",
     "iopub.status.busy": "2025-10-28T12:26:42.500256Z",
     "iopub.status.idle": "2025-10-28T12:26:42.508339Z",
     "shell.execute_reply": "2025-10-28T12:26:42.507974Z",
     "shell.execute_reply.started": "2025-10-28T12:26:42.500509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9458, start: 115, end: 122, answer: Beijing\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the capital of China?\",\n",
    "    context=\"On 1 October 1949, CCP Chairman Mao Zedong formally proclaimed the People's Republic of China in Tiananmen Square, Beijing.\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad3c4c2-4a36-4970-b174-6af13494804b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:26:59.833052Z",
     "iopub.status.busy": "2025-10-28T12:26:59.832778Z",
     "iopub.status.idle": "2025-10-28T12:39:20.759994Z",
     "shell.execute_reply": "2025-10-28T12:39:20.759583Z",
     "shell.execute_reply.started": "2025-10-28T12:26:59.833037Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3964933a1447088b9d91256123383a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9152008a7145a18dafbfb1a7b1d3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c7860199064786b93bd260b0cd36d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6037441ec249467fb82ef870362b9d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a91083c95d846eaaa0a19ee6ca37ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"t5-base\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e373d567-1a39-478a-b2d2-9125076c5908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:39:47.694023Z",
     "iopub.status.busy": "2025-10-28T12:39:47.693761Z",
     "iopub.status.idle": "2025-10-28T12:39:49.098815Z",
     "shell.execute_reply": "2025-10-28T12:39:49.098445Z",
     "shell.execute_reply.started": "2025-10-28T12:39:47.694008Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 128. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decoder architectures with multi-headed self-attention . for translation tasks, the Transformer can be trained significantly faster than architectures based on convolutional layers .'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff7e6081-f5c6-46b5-b685-fbaf552c56a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T12:40:01.563434Z",
     "iopub.status.busy": "2025-10-28T12:40:01.563162Z",
     "iopub.status.idle": "2025-10-28T12:40:02.463171Z",
     "shell.execute_reply": "2025-10-28T12:40:02.462785Z",
     "shell.execute_reply.started": "2025-10-28T12:40:01.563420Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 182. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'large language models (LLMs) are very large deep learning models pre-trained on vast amounts of data . transformers are capable of unsupervised training, although a more precise explanation is that they perform self-learning . data scientists can use GPUs for training transformer-based LLMs, significantly reducing the training time .'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    '''\n",
    "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data. \n",
    "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. \n",
    "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
    "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning. \n",
    "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
    "    Unlike earlier recurrent neural networks (RNN) that sequentially process inputs, transformers process entire sequences in parallel. \n",
    "    This allows the data scientists to use GPUs for training transformer-based LLMs, significantly reducing the training time.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3758a6-e451-4b79-868c-7e773b8076a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "share": {
   "datetime": "2025-10-28T11:44:46.673Z",
   "image": {
    "name": "modelscope:1.29.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04",
    "url": "dsw-registry-vpc.cn-shenzhen.cr.aliyuncs.com/pai/modelscope:1.29.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04"
   },
   "instance": "dsw-rc0857j29uaq85b4ts",
   "spec": {
    "id": "ecs.gn7i-c8g1.2xlarge",
    "type": "GPU"
   },
   "uid": "1430856208617895"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
